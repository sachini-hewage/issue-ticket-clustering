{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1b594b-004e-4914-b2c0-af3d3b184e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root to path \n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path(\"../\").resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee9a8bc-584c-42f2-b4a1-48ebb048bc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from src.clustering_utils_hdbscan import (\n",
    "    fetch_embeddings,\n",
    "    reduce_dimensions,\n",
    "    cluster_embeddings,\n",
    "    save_clusters,\n",
    "    soft_assign_noise,\n",
    "    get_cluster_representatives,\n",
    "    label_clusters_llm,\n",
    "    save_cluster_labels,\n",
    "    save_cluster_labels_to_table\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1d0ab7-1f23-4eeb-9d54-d6c6b7f89410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch embeddings\n",
    "df = fetch_embeddings(limit=None)\n",
    "print(f\"Fetched {len(df)} ticket embeddings for clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec7455d-35b8-4fcb-9767-2928575d4feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare numpy array for UMAP dim reduction\n",
    "X = np.array(df[\"embedding\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffbe9fe-b1b6-4f2f-894f-a7249a79a135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality reduction with UMAP\n",
    "# n_neighbors: controls local structure sensitivity (10–30 typically, I will use 30)\n",
    "# n_components: final embedding dimensions (10–50, I will try with 50 )\n",
    "X_reduced, reducer = reduce_dimensions(X, n_components=50, n_neighbors=30)\n",
    "print(f\"Reduced embeddings shape: {X_reduced.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8cea7e-a06e-468c-8f06-d8fdbc987d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster reduced embeddings using HDBSCAN\n",
    "# min_cluster_size: smaller = more fine-grained clusters, i will use 10 \n",
    "\n",
    "labels, clusterer = cluster_embeddings(X_reduced, min_cluster_size=50)\n",
    "\n",
    "# Soft-assign noise points that are above a threshold of similarity to the nearest cluster centers\n",
    "labels_soft = soft_assign_noise(X_reduced, labels, similarity_threshold= 0.999)\n",
    "df[\"cluster_id\"] = labels_soft\n",
    "\n",
    "print(f\"Found {len(set(labels_soft)) - (1 if -1 in labels else 0)} clusters\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d625652-864d-4115-afb9-3bf6ae636ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cluster labels back to Postgres\n",
    "save_clusters(df[[\"ticket_id\", \"cluster_id\"]])\n",
    "print(\"Cluster labels saved to Postgres\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174389da-c817-4851-93a9-4ccd1dd62752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "from src.config import DB_URL\n",
    "\n",
    "engine = create_engine(DB_URL)\n",
    "cluster_id = -1  # noise points\n",
    "\n",
    "query = text(\"\"\"\n",
    "    SELECT \n",
    "        p.ticket_id,\n",
    "        p.keywords\n",
    "    FROM \n",
    "        ticket_preprocessed p\n",
    "    JOIN \n",
    "        ticket_embeddings e \n",
    "    ON \n",
    "        p.ticket_id = e.ticket_id\n",
    "    WHERE \n",
    "        e.cluster_id = :cluster_id\n",
    "        AND p.keywords IS NOT NULL;\n",
    "\"\"\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df_interested = pd.read_sql(query, conn, params={\"cluster_id\": cluster_id})\n",
    "\n",
    "print(len(df_interested))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93986216-476e-414f-bb73-ec27b4b23e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc12001c-5d87-4ae8-a281-509f9529e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a55203-f0f5-433a-aec3-e7c6caa16fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find representatives of each cluster\n",
    "representatives = get_cluster_representatives(df, X_reduced, top_n=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0980be-d34f-4e05-a9e7-a40ce013b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Ensure the models directory exists\n",
    "os.makedirs(\"../models\", exist_ok=True)  # adjust path relative to your notebook\n",
    "\n",
    "# Save the models to files inside the models folder\n",
    "with open(\"../models/hdbscan_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(clusterer, f)\n",
    "\n",
    "with open(\"../models/umap_reducer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(reducer, f)\n",
    "\n",
    "print(\"Models saved successfully under '../models/'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdfb08d-cc42-4890-8fe8-aa665e64035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate natural language cluster labels\n",
    "cluster_labels = label_clusters_llm(df, representatives, max_tickets=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad65e163-eee2-4af1-9a31-ff9f0954b58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cluster labels to DB\n",
    "save_cluster_labels(cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4bd00e-dcf4-40a6-9a40-b8e113927e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Postgres\n",
    "save_cluster_labels_to_table(cluster_labels)\n",
    "print(\"Cluster labels saved to Postgres successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d608a5-86fe-4cf3-a72e-673c6c198006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76732cf-ee22-47ce-9ffb-8ab8d0d13749",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (enfuce-ai)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
